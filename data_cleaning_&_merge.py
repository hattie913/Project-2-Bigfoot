# -*- coding: utf-8 -*-
"""data_cleaning_&_merge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QQhTG9LflwJLqU4fBF6BSRPGooM84EDo
"""

!pip install geopandas

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import geopandas
import matplotlib.pyplot as plt

pd.set_option('display.max_rows',5000)
pd.set_option('display.max_columns', 500)

bigfootDF = pd.read_csv('bigfoot.csv')
countyDF = pd.read_csv('county_data.csv')
county = geopandas.read_file('cb_2018_us_county_5m.shp')

#drop states outside US contiguous states
indexName = county[county.STATEFP.isin(['15','02','60','66','69','72','78'])].index
continental_county = county.drop(index = indexName)

continental_county.to_crs('EPSG:4326')

continental_county.to_pickle('counties_clean.pkl')

counties = pd.read_pickle('counties_clean.pkl')

loc_notNA = bigfootDF.dropna(subset = ['latitude','longitude'])

geoBF = geopandas.GeoDataFrame(loc_notNA, crs="EPSG:4326", 
                                geometry=geopandas.points_from_xy(loc_notNA.longitude, loc_notNA.latitude))

#Make a single polygon for the contiguous US
from shapely.ops import cascaded_union
usa = geopandas.GeoSeries(cascaded_union(counties.geometry),crs = 4326)

geoBF = geoBF[geoBF.geometry.within(usa[0])]
geoBF.head()

"""# decide which counties have the bigfoot sightingsï¼š


"""

for sighting in geoBF.index:
    is_in_county = [geoBF.geometry[sighting].within(poly) for poly in counties.geometry]
    geoBF.loc[sighting, 'FIPS'] = counties[is_in_county].GEOID.values
geoBF.to_pickle('bigfoot_geo.pkl')

bigfoot_geo = pd.read_pickle('bigfoot_geo.pkl')
bigfoot_geo.rename(columns = {'FIPS':'fips'},inplace= True)
bigfoot_geo.tail()

"""# *Prepare CountyDF & Merge with bigfoot_geo and other dataframes* """

"""!pip install pickle5
import pickle5 as pickle

"""with open('county_labels.pkl', 'rb') as handle:
  county_labels = pickle.load(handle)

print(county_labels.head())

county_labels = pd.read_pickle('/content/county_labels.pkl')
indexName = county_labels[county_labels.state.isin(['AK','HI','AS','GU','MP','PR','VI'])].index
continental_county_labels = county_labels.drop(index = indexName)
state_list = list(continental_county_labels['state_name'].unique()) #generate a list of unqiue state names from continential_county_labels
print(state_list)
#print(len(state_list)) #49 states

#create new county data dataframe only include county data across the 49 states *******
continental_countyDF = countyDF[countyDF['state'].isin(state_list)] #extract the rows that do not contain Hawanii, Alaska and US territies in the state column
print(continental_countyDF.head())
print(continental_countyDF.info())

#Check the county column in clean county labels dataset (continental_county_labels)
county_list = list(continental_county_labels['county'].unique()) #generate a list of unqiue county names from continential_county_labels
print(sorted(county_list)) 

#Loop through the county_list to find any names contained 'County' and 'City' and store them in new lists
county_contain_county = []
county_contain_city = []

for county in county_list:
  if 'County' in county:
    #print("*****", county) 
    county_contain_county.append(county)
  elif 'City' in county:
    #print(county)
    county_contain_city.append(county)

print("")
print("****contain 'County': ", len(county_contain_county)) #No word 'County' is found; the word 'County' should not appear in the county_data
print("conatin 'City': ", len(county_contain_city)) #45 is found

#Check the county column in clean continental county dataset (continental_countyDF)
county_list_from_continental_countyDF = list(continental_countyDF['county'].astype(str).unique()) #generate a list of unqiue county names from continential_countyDF
print(sorted(county_list_from_continental_countyDF))

#Loop through the county_list to find any names contained 'County' and 'City' and store them in new lists
county_from_ccDF_contain_county = []
county_from_ccDF_contain_city = []

for county in county_list_from_continental_countyDF:
  if 'County' in county: 
    #print("*****", county) 
    county_from_ccDF_contain_county.append(county)
  elif 'City' in county:
    #print(county)
    county_from_ccDF_contain_city.append(county)

print("")
print("****contain 'County': ", len(county_from_ccDF_contain_county)) #need to remove all word 'County'
print("conatin 'City': ", len(county_from_ccDF_contain_city)) #need to double check whether they should be removed or not

#Compare the county column in both clean county labels (continental_county_labels) and countyDF
should_not_have_city = []

for city in county_from_ccDF_contain_city:
  if city not in county_contain_city:
    print(city)
    should_not_have_city.append(city) #need to further investigate

#continental_county_labels[continental_county_labels.county.str.contains('Colonial Heights')]

#continental_county_labels[continental_county_labels.county.str.contains('Washington')]

county_contain_city

#clean the continental_countyDF
continental_countyDF ['County'] = countyDF['county'].str.replace('County', '')
continental_countyDF ['County'] = continental_countyDF['County'].str.replace('.', '')
continental_countyDF ['County'] = continental_countyDF['County'].str.replace('\'', '')
continental_countyDF ['County'] = continental_countyDF['County'].replace('Washington City', 'Washington')
continental_countyDF ['County'] = continental_countyDF['County'].replace('Colonial Heights City', 'Colonial Heights Cit')  

continental_countyDF ['County'] = continental_countyDF['County'].str.strip()

#continental_countyDF.head()

continental_countyDF.head()

continental_county_labels.head()

bigfoot_geo.info()

# create a new bigfoot data dataframe ********************
# 1: merge bigfoot_geo and continental_county_labels together
bigfoot_county_labels = pd.merge(bigfoot_geo, continental_county_labels) 
print(bigfoot_county_labels.info())

# 2: merge bigfoot_county_labels and continental_countyDF together based on state and county name columns
bigfootDF_continental = bigfoot_county_labels.merge(continental_countyDF, how = 'inner', left_on = ["county", "state_name"], right_on = ["County","state"])
print(bigfootDF_continental.info()) #contain some redundant columns

#drop the redundant columns
bigfootDF_continental.drop(columns = ['state_y', 'county_y','County'], inplace = True)

print(bigfootDF_continental.head())
print(bigfootDF_continental.info()) #check the column infomation

#rename county_x and state_x to county and state
bigfootDF_continental.rename(columns = {"county_x": "county", "state_x": "state"}, inplace=True)

print(bigfootDF_continental.head()) #dispaly the merged dataframe to double check
print(bigfootDF_continental.info())

bigfootDF_continental.to_pickle('merge_bigfoot_continental.pkl')